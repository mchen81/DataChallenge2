{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d6984c6",
   "metadata": {},
   "source": [
    "# Part1. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3645456c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('cash or e-zpass train.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9550706",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "Before we make decisions, I want to take a look the shape of the data. This dataset contains 7 columns and 6,010,967 rows, which is really huge. To determine which feature should be kept or discarded, we can visuailize some attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33d1c2a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6010967 entries, 0 to 6010966\n",
      "Data columns (total 7 columns):\n",
      " #   Column                          Dtype \n",
      "---  ------                          ----- \n",
      " 0   Date                            object\n",
      " 1   Entrance                        object\n",
      " 2   Exit                            object\n",
      " 3   Interval Beginning Time         int64 \n",
      " 4   Vehicle Class                   object\n",
      " 5   Vehicle Count                   int64 \n",
      " 6   Payment Type (Cash or E-ZPass)  object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 321.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f641e30c",
   "metadata": {},
   "source": [
    "# Encoded features\n",
    "\n",
    "Because this dataset is a binary classification problem. We will train most models by classifiers instead of regressors. Most classifiers do not accept string based label, so we need to encoded each string based features. The encoding strategy is label encoding because it's the most suitable approach for classifiers. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95d5f58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "\n",
    "encoded_df = df.copy()\n",
    "encoded_df.drop('Date', axis=1)\n",
    "encoded_df['Vehicle Class'] = labelencoder.fit_transform(df['Vehicle Class'])\n",
    "encoded_df['Entrance'] = labelencoder.fit_transform(df['Entrance'])\n",
    "encoded_df['Exit'] = labelencoder.fit_transform(df['Exit'])\n",
    "encoded_df['Payment Type (Cash or E-ZPass)'] = labelencoder.fit_transform(df['Payment Type (Cash or E-ZPass)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f59e55",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "This dataset contains 6 features, which are Date, Entrace, Exit, Interval Beginning Time, Vehicle Class, and Vehicle Count. To predict the payment type, I believe the interval beginning time and Vehicle Class are the most  important feature because they are directly related the target. And I am not sure about how important the Date, Entrace, Exit and Vehicle count would be. Therefore, I want to train models by decision tree with 4 different combination of these features and see which one is better. \n",
    "\n",
    "1. Interval Beginning Time, Vehicle Class\n",
    "2. Interval Beginning Time, Vehicle Class, Entrance, Exit,\n",
    "3. Interval Beginning Time, Vehicle Class, Vehicle Count\n",
    "4. Interval Beginning Time, Vehicle Class, Date\n",
    "5. All features excluded date\n",
    "6. All features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54206c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df['Payment Type (Cash or E-ZPass)']\n",
    "\n",
    "date = df['Date'].apply(lambda x: x.split('/'))\n",
    "\n",
    "month = date.apply(lambda date: int(date[0]))\n",
    "day = date.apply(lambda date: int(date[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed3b035d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_1 = encoded_df[['Interval Beginning Time', 'Vehicle Class']]\n",
    "dataset_2 = encoded_df[['Interval Beginning Time', 'Vehicle Class', 'Entrance', 'Exit']]\n",
    "dataset_3 = encoded_df[['Interval Beginning Time', 'Vehicle Class', 'Vehicle Count']]\n",
    "\n",
    "dataset_4 = dataset_1.copy()\n",
    "dataset_4['day'] = day\n",
    "dataset_4['month'] = month\n",
    "\n",
    "dataset_5 = encoded_df[['Interval Beginning Time', 'Vehicle Class', 'Entrance', 'Exit', 'Vehicle Count']]\n",
    "\n",
    "dataset_6 = dataset_5.copy()\n",
    "dataset_6['day'] = day\n",
    "dataset_6['month'] = month"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76d2200",
   "metadata": {},
   "source": [
    "# Decision Tree\n",
    "\n",
    "Since this dataset has more than 6 millions rows, to efficiently determine which dataset is the best, we don't want the chosed algorithm takes too much time. Therefore, here I choose the decision tree classifier because it is the most reliable and fast algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84ae9a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def decision_tree_accuracy(features, target):\n",
    "    train_x, test_x, train_y, test_y = train_test_split(features, target, test_size=0.3, random_state=11)\n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf.fit(train_x, train_y)\n",
    "    hyp = clf.predict(test_x)\n",
    "    return accuracy_score(test_y, hyp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13a2ff99",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [dataset_1, dataset_2, dataset_3, dataset_4, dataset_5, dataset_6]\n",
    "accuracies = [None] * len(datasets)\n",
    "\n",
    "for i in range(len(datasets)):\n",
    "    accuracies[i] = decision_tree_accuracy(datasets[i], target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba4b2e9",
   "metadata": {},
   "source": [
    "# Result\n",
    "\n",
    "As the following cell shows, the best features set is dataset-5, which has the features: **Interval Beginning Time, Vehicle Class, Entrance, Exit, Vehicle Count**.  \n",
    "Therefore, I will select these feature in the future processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbed1aa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6880891658639676,\n",
       " 0.6673493074606373,\n",
       " 0.6876860140709403,\n",
       " 0.6862170331909825,\n",
       " 0.7317787312197532,\n",
       " 0.6743531687342753]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
